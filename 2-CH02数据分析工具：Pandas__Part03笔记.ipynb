{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n【课程2.14】  数值计算和统计基础\\n\\n常用数学、统计方法\\n \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "【课程2.14】  数值计算和统计基础\n",
    "\n",
    "常用数学、统计方法\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key1  key2 key3\n",
      "a   4.0   1.0    1\n",
      "b   5.0   2.0    2\n",
      "c   3.0   NaN    3\n",
      "d   NaN   4.0    j\n",
      "e   2.0   5.0    k\n",
      "float64 float64 object\n",
      "-----\n",
      "key1    3.5\n",
      "key2    3.0\n",
      "dtype: float64 <class 'pandas.core.series.Series'>\n",
      "a    2.5\n",
      "b    3.5\n",
      "c    3.0\n",
      "d    4.0\n",
      "e    3.5\n",
      "dtype: float64\n",
      "a    2.5\n",
      "b    3.5\n",
      "c    NaN\n",
      "d    NaN\n",
      "e    3.5\n",
      "dtype: float64\n",
      "key1    3.5\n",
      "key2    3.0\n",
      "dtype: float64 <class 'pandas.core.series.Series'>\n",
      "单独统计一列: 3.0\n",
      "-----\n",
      "a    2.5\n",
      "b    3.5\n",
      "c    3.0\n",
      "d    4.0\n",
      "e    3.5\n",
      "dtype: float64\n",
      "-----\n",
      "key1   NaN\n",
      "key2   NaN\n",
      "dtype: float64\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 基本参数：axis、skipna\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'key1':[4,5,3,np.nan,2],\n",
    "                 'key2':[1,2,np.nan,4,5],\n",
    "                 'key3':[1,2,3,'j','k']},\n",
    "                 index = ['a','b','c','d','e'])\n",
    "print(df)\n",
    "print(df['key1'].dtype,df['key2'].dtype,df['key3'].dtype)\n",
    "print('-----')\n",
    "\n",
    "print(df.mean(),type(df.mean()))\n",
    "print(df.mean(axis = 1))\n",
    "print(df.mean(axis = 1, skipna = False))   #与空值有关的都为空值\n",
    "\n",
    "\n",
    "m1 = df.mean()\n",
    "print(m1,type(m1))\n",
    "print('单独统计一列:',df['key2'].mean())\n",
    "print('-----')\n",
    "# np.nan ：空值\n",
    "# .mean()计算均值\n",
    "# 只统计数字列\n",
    "# 可以通过索引单独统计一列\n",
    "\n",
    "m2 = df.mean(axis=1)\n",
    "print(m2)\n",
    "print('-----')\n",
    "# axis参数：默认为0，以列来计算，axis=1，以行来计算，这里就按照行来汇总了\n",
    "\n",
    "m3 = df.mean(skipna=False)\n",
    "print(m3)\n",
    "print('-----')\n",
    "# skipna参数：是否忽略NaN，默认True，如False，有NaN的列统计结果仍未NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key1      key2\n",
      "0     0  5.801278\n",
      "1     1  0.747773\n",
      "2     2  6.858544\n",
      "3     3  4.347099\n",
      "4     4  9.201321\n",
      "5     5  3.277330\n",
      "6     6  3.930217\n",
      "7     7  7.896461\n",
      "8     8  3.436647\n",
      "9     9  7.350309\n",
      "-----\n",
      "key1    10\n",
      "key2    10\n",
      "dtype: int64 → count统计非Na值的数量\n",
      "\n",
      "key1    0.000000\n",
      "key2    0.747773\n",
      "dtype: float64 → min统计最小值\n",
      " 9.201320544496754 → max统计最大值\n",
      "\n",
      "key1    6.750000\n",
      "key2    7.227367\n",
      "Name: 0.75, dtype: float64 → quantile统计分位数，参数q确定位置\n",
      "\n",
      "key1    45.000000\n",
      "key2    52.846979\n",
      "dtype: float64 → sum求和\n",
      "\n",
      "key1    4.500000\n",
      "key2    5.284698\n",
      "dtype: float64 → mean求平均值\n",
      "\n",
      "key1    4.500000\n",
      "key2    5.074189\n",
      "dtype: float64 → median求算数中位数，50%分位数\n",
      "\n",
      "key1    3.027650\n",
      "key2    2.580139\n",
      "dtype: float64 \n",
      " key1    9.166667\n",
      "key2    6.657117\n",
      "dtype: float64 → std,var分别求标准差，方差\n",
      "\n",
      "key1    0.000000\n",
      "key2   -0.164553\n",
      "dtype: float64 → skew样本的偏度\n",
      "\n",
      "key1   -1.200000\n",
      "key2   -0.586658\n",
      "dtype: float64 → kurt样本的峰度\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 主要数学计算方法，可用于Series和DataFrame（1）\n",
    "\n",
    "df = pd.DataFrame({'key1':np.arange(10),\n",
    "                  'key2':np.random.rand(10)*10})\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "print(df.count(),'→ count统计非Na值的数量\\n')\n",
    "print(df.min(),'→ min统计最小值\\n',df['key2'].max(),'→ max统计最大值\\n')\n",
    "print(df.quantile(q=0.75),'→ quantile统计分位数，参数q确定位置\\n')\n",
    "print(df.sum(),'→ sum求和\\n')\n",
    "print(df.mean(),'→ mean求平均值\\n')\n",
    "print(df.median(),'→ median求算数中位数，50%分位数\\n')\n",
    "print(df.std(),'\\n',df.var(),'→ std,var分别求标准差，方差\\n')\n",
    "print(df.skew(),'→ skew样本的偏度\\n')\n",
    "print(df.kurt(),'→ kurt样本的峰度\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   key1      key2  key1_s     key2_s\n",
      "0     0  5.801278       0   5.801278\n",
      "1     1  0.747773       1   6.549051\n",
      "2     2  6.858544       3  13.407595\n",
      "3     3  4.347099       6  17.754694\n",
      "4     4  9.201321      10  26.956014\n",
      "5     5  3.277330      15  30.233344\n",
      "6     6  3.930217      21  34.163562\n",
      "7     7  7.896461      28  42.060023\n",
      "8     8  3.436647      36  45.496670\n",
      "9     9  7.350309      45  52.846979 → cumsum样本的累计和\n",
      "\n",
      "   key1      key2  key1_s     key2_s  key1_p        key2_p\n",
      "0     0  5.801278       0   5.801278       0  5.801278e+00\n",
      "1     1  0.747773       1   6.549051       0  4.338039e+00\n",
      "2     2  6.858544       3  13.407595       0  2.975263e+01\n",
      "3     3  4.347099       6  17.754694       0  1.293376e+02\n",
      "4     4  9.201321      10  26.956014       0  1.190077e+03\n",
      "5     5  3.277330      15  30.233344       0  3.900275e+03\n",
      "6     6  3.930217      21  34.163562       0  1.532893e+04\n",
      "7     7  7.896461      28  42.060023       0  1.210443e+05\n",
      "8     8  3.436647      36  45.496670       0  4.159865e+05\n",
      "9     9  7.350309      45  52.846979       0  3.057629e+06 → cumprod样本的累计积\n",
      "\n",
      "   key1      key2  key1_s     key2_s  key1_p        key2_p\n",
      "0   0.0  5.801278     0.0   5.801278     0.0  5.801278e+00\n",
      "1   1.0  5.801278     1.0   6.549051     0.0  5.801278e+00\n",
      "2   2.0  6.858544     3.0  13.407595     0.0  2.975263e+01\n",
      "3   3.0  6.858544     6.0  17.754694     0.0  1.293376e+02\n",
      "4   4.0  9.201321    10.0  26.956014     0.0  1.190077e+03\n",
      "5   5.0  9.201321    15.0  30.233344     0.0  3.900275e+03\n",
      "6   6.0  9.201321    21.0  34.163562     0.0  1.532893e+04\n",
      "7   7.0  9.201321    28.0  42.060023     0.0  1.210443e+05\n",
      "8   8.0  9.201321    36.0  45.496670     0.0  4.159865e+05\n",
      "9   9.0  9.201321    45.0  52.846979     0.0  3.057629e+06 \n",
      "    key1      key2  key1_s    key2_s  key1_p    key2_p\n",
      "0   0.0  5.801278     0.0  5.801278     0.0  5.801278\n",
      "1   0.0  0.747773     0.0  5.801278     0.0  4.338039\n",
      "2   0.0  0.747773     0.0  5.801278     0.0  4.338039\n",
      "3   0.0  0.747773     0.0  5.801278     0.0  4.338039\n",
      "4   0.0  0.747773     0.0  5.801278     0.0  4.338039\n",
      "5   0.0  0.747773     0.0  5.801278     0.0  4.338039\n",
      "6   0.0  0.747773     0.0  5.801278     0.0  4.338039\n",
      "7   0.0  0.747773     0.0  5.801278     0.0  4.338039\n",
      "8   0.0  0.747773     0.0  5.801278     0.0  4.338039\n",
      "9   0.0  0.747773     0.0  5.801278     0.0  4.338039 → cummax,cummin分别求累计最大值，累计最小值\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 主要数学计算方法，可用于Series和DataFrame（2）\n",
    "\n",
    "df['key1_s'] = df['key1'].cumsum()\n",
    "df['key2_s'] = df['key2'].cumsum()\n",
    "print(df,'→ cumsum样本的累计和\\n')\n",
    "\n",
    "df['key1_p'] = df['key1'].cumprod()\n",
    "df['key2_p'] = df['key2'].cumprod()\n",
    "print(df,'→ cumprod样本的累计积\\n')\n",
    "\n",
    "print(df.cummax(),'\\n',df.cummin(),'→ cummax,cummin分别求累计最大值，累计最小值\\n')\n",
    "# 会填充key1，和key2的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     a\n",
      "1     s\n",
      "2     d\n",
      "3     v\n",
      "4     a\n",
      "5     s\n",
      "6     d\n",
      "7     c\n",
      "8     f\n",
      "9     g\n",
      "10    g\n",
      "dtype: object\n",
      "['a' 's' 'd' 'v' 'c' 'f' 'g'] <class 'numpy.ndarray'>\n",
      "0    a\n",
      "1    s\n",
      "2    d\n",
      "3    v\n",
      "4    c\n",
      "5    f\n",
      "6    g\n",
      "dtype: object\n",
      "['a' 'c' 'd' 'f' 'g' 's' 'v']\n"
     ]
    }
   ],
   "source": [
    "# 唯一值：.unique()\n",
    "\n",
    "s = pd.Series(list('asdvasdcfgg'))\n",
    "sq = s.unique()\n",
    "print(s)\n",
    "print(sq,type(sq))\n",
    "print(pd.Series(sq))\n",
    "# 得到一个唯一值数组\n",
    "# 通过pd.Series重新变成新的Series\n",
    "\n",
    "sq.sort()\n",
    "print(sq)\n",
    "# 重新排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g    2\n",
      "c    1\n",
      "s    2\n",
      "v    1\n",
      "d    2\n",
      "a    2\n",
      "f    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 值计数：.value_counts()\n",
    "\n",
    "sc = s.value_counts(sort = False)  # 也可以这样写：pd.value_counts(sc, sort = False)\n",
    "print(sc)\n",
    "# 得到一个新的Series，计算出不同值出现的频率\n",
    "# sort参数：排序，默认为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10\n",
      "1    11\n",
      "2    12\n",
      "3    13\n",
      "4    14\n",
      "dtype: int32\n",
      "  key1  key2\n",
      "0    a     4\n",
      "1    s     5\n",
      "2    d     6\n",
      "3    c     7\n",
      "4    b     8\n",
      "5    v     9\n",
      "6    a    10\n",
      "7    s    11\n",
      "8    d    12\n",
      "-----\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "dtype: bool\n",
      "    key1   key2\n",
      "0   True  False\n",
      "1  False  False\n",
      "2  False  False\n",
      "3  False  False\n",
      "4  False   True\n",
      "5  False  False\n",
      "6   True  False\n",
      "7  False  False\n",
      "8  False  False\n"
     ]
    }
   ],
   "source": [
    "# 成员资格：.isin()\n",
    "\n",
    "s = pd.Series(np.arange(10,15))\n",
    "df = pd.DataFrame({'key1':list('asdcbvasd'),\n",
    "                  'key2':np.arange(4,13)})\n",
    "print(s)\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "print(s.isin([5,14]))\n",
    "print(df.isin(['a','bc','10',8]))\n",
    "# 用[]表示\n",
    "# 得到一个布尔值的Series或者Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        key1       key2\n",
      "0   6.361889  86.757346\n",
      "1  31.567349  52.564604\n",
      "2  81.356918  96.524049\n",
      "3  67.776597  54.559212\n",
      "4  54.253346  79.736096\n",
      "key1均值为: 39.98979516585428\n",
      "key1中位数为： 42.910347384200776\n",
      "key2均值为: 74.02826146189841\n",
      "key2中位数为： 79.73609567409751\n",
      "df的累积和为：\n",
      "         key1       key2  key1_cumsum  key2_cumsum\n",
      "0   6.361889  86.757346     6.361889    86.757346\n",
      "1  31.567349  52.564604    37.929238   139.321950\n",
      "2        NaN  96.524049          NaN   235.845999\n",
      "3  67.776597  54.559212   105.705835   290.405212\n",
      "4  54.253346  79.736096   159.959181   370.141307\n"
     ]
    }
   ],
   "source": [
    "#作业\n",
    "\n",
    "t = pd.DataFrame(np.random.rand(10).reshape(5,2)*100,\n",
    "            columns = ('key1','key2'))\n",
    "print(t)\n",
    "t['key1'][2] = np.nan\n",
    "t['key1_cumsum'] = t['key1'].cumsum()\n",
    "t['key2_cumsum'] = t['key2'].cumsum()\n",
    "print('key1均值为:',t['key1'].mean())\n",
    "print('key1中位数为：',t['key1'].median())\n",
    "print('key2均值为:',t['key2'].mean())\n",
    "print('key2中位数为：',t['key2'].median())\n",
    "print('df的累积和为：\\n',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#作业2\n",
    "def f(x):\n",
    "    x1 = x.unique()\n",
    "    if len(x) == len(x1):\n",
    "        print('该数组为唯一值数组')\n",
    "    else:\n",
    "        print('该数组不是唯一值数组')\n",
    "d = input('请输入一组元素，用逗号（英文符号）隔开：\\n')\n",
    "lst = d.split(',')\n",
    "a = pd.Series(lst)\n",
    "f(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "【课程2.15】  文本数据\n",
    "\n",
    "Pandas针对字符串配备的一套方法，使其易于对数组的每个元素进行操作\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          A\n",
      "1          b\n",
      "2          C\n",
      "3    bbhello\n",
      "4        123\n",
      "5        NaN\n",
      "6         hj\n",
      "dtype: object\n",
      "  key1  key2\n",
      "0    a   hee\n",
      "1    b    fv\n",
      "2    c     w\n",
      "3    d  hija\n",
      "4    e   123\n",
      "5    f   NaN\n",
      "-----\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    2.0\n",
      "4    0.0\n",
      "5    NaN\n",
      "6    0.0\n",
      "dtype: float64\n",
      "0     HEE\n",
      "1      FV\n",
      "2       W\n",
      "3    HIJA\n",
      "4     123\n",
      "5     NaN\n",
      "Name: key2, dtype: object\n",
      "-----\n",
      "  KEY1  KEY2\n",
      "0    a   hee\n",
      "1    b    fv\n",
      "2    c     w\n",
      "3    d  hija\n",
      "4    e   123\n",
      "5    f   NaN\n"
     ]
    }
   ],
   "source": [
    "# 通过str访问，且自动排除丢失/ NA值\n",
    "\n",
    "s = pd.Series(['A','b','C','bbhello','123',np.nan,'hj'])\n",
    "df = pd.DataFrame({'key1':list('abcdef'),\n",
    "                  'key2':['hee','fv','w','hija','123',np.nan]})\n",
    "print(s)\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "print(s.str.count('b'))\n",
    "print(df['key2'].str.upper())\n",
    "print('-----')\n",
    "# 直接通过.str调用字符串方法\n",
    "# 可以对Series、Dataframe使用\n",
    "# 自动过滤NaN值\n",
    "\n",
    "\n",
    "df.columns = df.columns.str.upper()\n",
    "print(df)\n",
    "# df.columns是一个Index对象，也可使用.str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          a\n",
      "1          b\n",
      "2    bbhello\n",
      "3        123\n",
      "4        NaN\n",
      "dtype: object → lower小写\n",
      "\n",
      "0          A\n",
      "1          B\n",
      "2    BBHELLO\n",
      "3        123\n",
      "4        NaN\n",
      "dtype: object → upper大写\n",
      "\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    7.0\n",
      "3    3.0\n",
      "4    NaN\n",
      "dtype: float64 → len字符长度\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4      NaN\n",
      "dtype: object → 判断起始是否为a\n",
      "\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4      NaN\n",
      "dtype: object → 判断结束是否为3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 字符串常用方法（1） - lower，upper，len，startswith，endswith\n",
    "\n",
    "s = pd.Series(['A','b','bbhello','123',np.nan])\n",
    "\n",
    "print(s.str.lower(),'→ lower小写\\n')\n",
    "print(s.str.upper(),'→ upper大写\\n')\n",
    "print(s.str.len(),'→ len字符长度\\n')\n",
    "print(s.str.startswith('b'),'→ 判断起始是否为a\\n')\n",
    "print(s.str.endswith('3'),'→ 判断结束是否为3\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       jack\n",
      "1      jill \n",
      "2     jesse \n",
      "3      frank\n",
      "dtype: object\n",
      "    Column A    Column B \n",
      "0    1.268043    0.350617\n",
      "1   -0.776499   -0.756303\n",
      "2    1.018243   -1.331820\n",
      "-----\n",
      "0     jack\n",
      "1     jill\n",
      "2    jesse\n",
      "3    frank\n",
      "dtype: object\n",
      "0      jack\n",
      "1     jill \n",
      "2    jesse \n",
      "3     frank\n",
      "dtype: object\n",
      "0      jack\n",
      "1      jill\n",
      "2     jesse\n",
      "3     frank\n",
      "dtype: object\n",
      "   Column A  Column B\n",
      "0  1.268043  0.350617\n",
      "1 -0.776499 -0.756303\n",
      "2  1.018243 -1.331820\n"
     ]
    }
   ],
   "source": [
    "# 字符串常用方法（2） - strip\n",
    "\n",
    "s = pd.Series([' jack', 'jill ', ' jesse ', 'frank'])\n",
    "df = pd.DataFrame(np.random.randn(3, 2), columns=[' Column A ', ' Column B '],\n",
    "                  index=range(3))\n",
    "print(s)\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "print(s.str.strip())  # 去除字符串中的空格\n",
    "print(s.str.lstrip())  # 去除字符串中的左空格\n",
    "print(s.str.rstrip())  # 去除字符串中的右空格\n",
    "\n",
    "df.columns = df.columns.str.strip()\n",
    "print(df)\n",
    "# 这里去掉了columns的前后空格，但没有去掉中间空格\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -Column-A-  -Column-B-\n",
      "0    3.011658    0.188124\n",
      "1   -1.442434    1.550728\n",
      "2    0.994254   -2.270058\n",
      "   heheColumn-A-  heheColumn-B-\n",
      "0       3.011658       0.188124\n",
      "1      -1.442434       1.550728\n",
      "2       0.994254      -2.270058\n"
     ]
    }
   ],
   "source": [
    "# 字符串常用方法（3） - replace\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(3, 2), columns=[' Column A ', ' Column B '],\n",
    "                  index=range(3))\n",
    "df.columns = df.columns.str.replace(' ','-')\n",
    "print(df)\n",
    "# 替换\n",
    "\n",
    "df.columns = df.columns.str.replace('-','hehe',n=1) #n=1,只替换第一个 \n",
    "print(df)\n",
    "# n：替换个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      a,b,c\n",
      "1      1,2,3\n",
      "2    [a,,,c]\n",
      "3        NaN\n",
      "dtype: object\n",
      "0    [a, b, c]\n",
      "1    [1, 2, 3]\n",
      "2          NaN\n",
      "3          NaN\n",
      "dtype: object\n",
      "-----\n",
      "['a', 'b', 'c']\n",
      "-----\n",
      "0      a\n",
      "1      1\n",
      "2    NaN\n",
      "3    NaN\n",
      "dtype: object\n",
      "0      b\n",
      "1      2\n",
      "2    NaN\n",
      "3    NaN\n",
      "dtype: object\n",
      "-----\n",
      "     0    1    2\n",
      "0    a    b    c\n",
      "1    1    2    3\n",
      "2  NaN  NaN  NaN\n",
      "3  NaN  NaN  NaN\n",
      "     0    1\n",
      "0    a  b,c\n",
      "1    1  2,3\n",
      "2  NaN  NaN\n",
      "3  NaN  NaN\n",
      "     0    1\n",
      "0  a,b    c\n",
      "1  1,2    3\n",
      "2  NaN  NaN\n",
      "3  NaN  NaN\n",
      "-----\n",
      "0    [a, b, c]\n",
      "1    [1, 2, 3]\n",
      "2          NaN\n",
      "Name: key2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 字符串常用方法（4） - split、rsplit\n",
    "\n",
    "s = pd.Series(['a,b,c','1,2,3',['a,,,c'],np.nan])\n",
    "print(s)\n",
    "print(s.str.split(','))\n",
    "print('-----')\n",
    "# 类似字符串的split\n",
    "\n",
    "print(s.str.split(',')[0])\n",
    "print('-----')\n",
    "# 直接索引得到一个list\n",
    "\n",
    "print(s.str.split(',').str[0])\n",
    "print(s.str.split(',').str.get(1))\n",
    "print('-----')\n",
    "# 可以使用get或[]符号访问拆分列表中的元素\n",
    "\n",
    "print(s.str.split(',', expand=True))\n",
    "print(s.str.split(',', expand=True, n = 1))\n",
    "print(s.str.rsplit(',', expand=True, n = 1))\n",
    "print('-----')\n",
    "# 可以使用expand可以轻松扩展此操作以返回DataFrame\n",
    "# n参数限制分割数\n",
    "# rsplit类似于split，反向工作，即从字符串的末尾到字符串的开头\n",
    "\n",
    "df = pd.DataFrame({'key1':['a,b,c','1,2,3',[':,., ']],\n",
    "                  'key2':['a-b-c','1-2-3',[':-.- ']]})\n",
    "print(df['key2'].str.split('-'))\n",
    "# Dataframe使用split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          A\n",
      "1          b\n",
      "2          C\n",
      "3    bbhello\n",
      "4        123\n",
      "5        NaN\n",
      "6         hj\n",
      "dtype: object\n",
      "0      A\n",
      "1      b\n",
      "2      C\n",
      "3      b\n",
      "4      1\n",
      "5    NaN\n",
      "6      h\n",
      "dtype: object\n",
      "0      A\n",
      "1      b\n",
      "2      C\n",
      "3     bb\n",
      "4     12\n",
      "5    NaN\n",
      "6     hj\n",
      "dtype: object\n",
      "0      h\n",
      "1      f\n",
      "2      w\n",
      "3      h\n",
      "4      1\n",
      "5    NaN\n",
      "Name: key2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 字符串索引\n",
    "\n",
    "s = pd.Series(['A','b','C','bbhello','123',np.nan,'hj'])\n",
    "df = pd.DataFrame({'key1':list('abcdef'),\n",
    "                  'key2':['hee','fv','w','hija','123',np.nan]})\n",
    "print(s)\n",
    "print(s.str[0])  # 取第一个字符串\n",
    "print(s.str[:2])  # 取前两个字符串\n",
    "print(df['key2'].str[0]) \n",
    "# str之后和字符串本身索引方式相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建DataFrame为：\n",
      "      name gender     score\n",
      "0    jack     M   90-92-89\n",
      "1     tom      M  89-78-88\n",
      "2   Marry      F  90-92-95\n",
      "3    zack     M   78-88-76\n",
      "4  heheda      F  60-60-67\n",
      "     name gender math english art\n",
      "0    Jack      M   90      92  89\n",
      "1     Tom      M   89      78  88\n",
      "2   Marry      F   90      92  95\n",
      "3    Zack      M   78      88  76\n",
      "4  Heheda      F   60      60  67\n"
     ]
    }
   ],
   "source": [
    "#作业\n",
    "df = pd.DataFrame({'name':['jack','tom','Marry','zack','heheda'],\n",
    "                  'gender':['M ','M','   F','  M ','  F'],\n",
    "                  'score':['90-92-89','89-78-88','90-92-95','78-88-76','60-60-67']})\n",
    "print('创建DataFrame为：\\n',df)\n",
    "df['name'] = df['name'].str.capitalize()\n",
    "df['gender'] = df['gender'].str.strip()\n",
    "df['math'] = df[\"score\"].str.split('-',expand = True)[0]\n",
    "df['english'] = df[\"score\"].str.split('-',expand = True)[1]\n",
    "df['art'] = df[\"score\"].str.split('-',expand = True)[2]\n",
    "del df['score']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n【课程2.16】  合并 merge、join\\n\\nPandas具有全功能的，高性能内存中连接操作，与SQL等关系数据库非常相似\\n\\npd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\\n         left_index=False, right_index=False, sort=True,\\n         suffixes=('_x', '_y'), copy=True, indicator=False)\\n \\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "【课程2.16】  合并 merge、join\n",
    "\n",
    "Pandas具有全功能的，高性能内存中连接操作，与SQL等关系数据库非常相似\n",
    "\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False)\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   A   B\n",
      "0  K0  A0  B0\n",
      "1  K1  A1  B1\n",
      "2  K2  A2  B2\n",
      "3  K3  A3  B3\n",
      "  key   C   D\n",
      "0  K0  C0  D0\n",
      "1  K1  C1  D1\n",
      "2  K2  C2  D2\n",
      "3  K3  C3  D3\n",
      "  key   A   B   C   D\n",
      "0  K0  A0  B0  C0  D0\n",
      "1  K1  A1  B1  C1  D1\n",
      "2  K2  A2  B2  C2  D2\n",
      "3  K3  A3  B3  C3  D3\n",
      "------\n",
      "  key1 key2   A   B\n",
      "0   K0   K0  A0  B0\n",
      "1   K0   K1  A1  B1\n",
      "2   K1   K0  A2  B2\n",
      "3   K2   K1  A3  B3\n",
      "  key1 key2   C   D\n",
      "0   K0   K0  C0  D0\n",
      "1   K1   K0  C1  D1\n",
      "2   K1   K0  C2  D2\n",
      "3   K2   K0  C3  D3\n",
      "  key1 key2   A   B   C   D\n",
      "0   K0   K0  A0  B0  C0  D0\n",
      "1   K1   K0  A2  B2  C1  D1\n",
      "2   K1   K0  A2  B2  C2  D2\n"
     ]
    }
   ],
   "source": [
    "# merge合并 → 类似excel的vlookup\n",
    "\n",
    "df1 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "df2 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "df3 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                    'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                    'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "df4 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                    'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(pd.merge(df1, df2, on='key'))\n",
    "print('------')\n",
    "# left：第一个df\n",
    "# right：第二个df\n",
    "# on：参考键\n",
    "print(df3)\n",
    "print(df4)\n",
    "print(pd.merge(df3, df4, on=['key1','key2']))\n",
    "# 多个链接键"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key1 key2   A   B   C   D\n",
      "0   K0   K0  A0  B0  C0  D0\n",
      "1   K1   K0  A2  B2  C1  D1\n",
      "2   K1   K0  A2  B2  C2  D2\n",
      "------\n",
      "  key1 key2    A    B    C    D\n",
      "0   K0   K0   A0   B0   C0   D0\n",
      "1   K0   K1   A1   B1  NaN  NaN\n",
      "2   K1   K0   A2   B2   C1   D1\n",
      "3   K1   K0   A2   B2   C2   D2\n",
      "4   K2   K1   A3   B3  NaN  NaN\n",
      "5   K2   K0  NaN  NaN   C3   D3\n",
      "------\n",
      "  key1 key2   A   B    C    D\n",
      "0   K0   K0  A0  B0   C0   D0\n",
      "1   K0   K1  A1  B1  NaN  NaN\n",
      "2   K1   K0  A2  B2   C1   D1\n",
      "3   K1   K0  A2  B2   C2   D2\n",
      "4   K2   K1  A3  B3  NaN  NaN\n",
      "------\n",
      "  key1 key2    A    B   C   D\n",
      "0   K0   K0   A0   B0  C0  D0\n",
      "1   K1   K0   A2   B2  C1  D1\n",
      "2   K1   K0   A2   B2  C2  D2\n",
      "3   K2   K0  NaN  NaN  C3  D3\n"
     ]
    }
   ],
   "source": [
    "# 参数how → 合并方式\n",
    "print(pd.merge(df3, df4,on=['key1','key2'], how = 'inner'))  \n",
    "print('------')\n",
    "# inner：默认，取交集\n",
    "\n",
    "print(pd.merge(df3, df4, on=['key1','key2'], how = 'outer'))  \n",
    "print('------')\n",
    "# outer：取并集，数据缺失范围NaN\n",
    "\n",
    "print(pd.merge(df3, df4, on=['key1','key2'], how = 'left'))  \n",
    "print('------')\n",
    "# left：按照df3为参考合并，数据缺失范围NaN\n",
    "\n",
    "print(pd.merge(df3, df4, on=['key1','key2'], how = 'right'))  \n",
    "# right：按照df4为参考合并，数据缺失范围NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lkey  data1 rkey  date2\n",
      "0    b      0    b      1\n",
      "1    b      1    b      1\n",
      "2    b      6    b      1\n",
      "3    a      2    a      0\n",
      "4    a      4    a      0\n",
      "5    a      5    a      0\n",
      "------\n",
      "  key  data1\n",
      "0   a      0\n",
      "1   b      1\n",
      "2   c      2\n",
      "3   d      3\n",
      "4   f      4\n",
      "5   e      5\n",
      "6   g      6\n",
      "   date2\n",
      "a    100\n",
      "b    101\n",
      "c    102\n",
      "d    103\n",
      "e    104\n",
      "  key  data1  date2\n",
      "0   a      0    100\n",
      "1   b      1    101\n",
      "2   c      2    102\n",
      "3   d      3    103\n",
      "5   e      5    104\n"
     ]
    }
   ],
   "source": [
    "# 参数 left_on, right_on, left_index, right_index → 当键不为一个列时，可以单独设置左键与右键\n",
    "\n",
    "df1 = pd.DataFrame({'lkey':list('bbacaab'),\n",
    "                   'data1':range(7)})\n",
    "df2 = pd.DataFrame({'rkey':list('abd'),\n",
    "                   'date2':range(3)})\n",
    "print(pd.merge(df1, df2, left_on='lkey', right_on='rkey'))\n",
    "print('------')\n",
    "# df1以‘lkey’为键，df2以‘rkey’为键\n",
    "\n",
    "df1 = pd.DataFrame({'key':list('abcdfeg'),\n",
    "                   'data1':range(7)})\n",
    "df2 = pd.DataFrame({'date2':range(100,105)},\n",
    "                  index = list('abcde'))\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(pd.merge(df1, df2, left_on='key', right_index=True))\n",
    "# df1以‘key’为键，df2以index为键\n",
    "# left_index：为True时，第一个df以index为键，默认False\n",
    "# right_index：为True时，第二个df以index为键，默认False\n",
    "\n",
    "# 所以left_on, right_on, left_index, right_index可以相互组合：\n",
    "# left_on + right_on, left_on + right_index, left_index + right_on, left_index + right_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  data1  date2\n",
      "0   b    1.0    2.0\n",
      "1   b    3.0    2.0\n",
      "2   b    7.0    2.0\n",
      "3   a    2.0   11.0\n",
      "4   a    5.0   11.0\n",
      "5   a    9.0   11.0\n",
      "6   c    4.0    NaN\n",
      "7   d    NaN   33.0\n",
      "  key  data1  date2\n",
      "0   a    2.0   11.0\n",
      "1   a    5.0   11.0\n",
      "2   a    9.0   11.0\n",
      "3   b    1.0    2.0\n",
      "4   b    3.0    2.0\n",
      "5   b    7.0    2.0\n",
      "6   c    4.0    NaN\n",
      "7   d    NaN   33.0\n",
      "------\n",
      "  key  data1  date2\n",
      "3   b    1.0    2.0\n",
      "0   a    2.0   11.0\n",
      "4   b    3.0    2.0\n",
      "6   c    4.0    NaN\n",
      "1   a    5.0   11.0\n",
      "5   b    7.0    2.0\n",
      "2   a    9.0   11.0\n",
      "7   d    NaN   33.0\n"
     ]
    }
   ],
   "source": [
    "# 参数 sort\n",
    "\n",
    "df1 = pd.DataFrame({'key':list('bbacaab'),\n",
    "                   'data1':[1,3,2,4,5,9,7]})\n",
    "df2 = pd.DataFrame({'key':list('abd'),\n",
    "                   'date2':[11,2,33]})\n",
    "x1 = pd.merge(df1,df2, on = 'key', how = 'outer')\n",
    "x2 = pd.merge(df1,df2, on = 'key', sort=True, how = 'outer')\n",
    "print(x1)\n",
    "print(x2)\n",
    "print('------')\n",
    "# sort：按照字典顺序通过 连接键 对结果DataFrame进行排序。默认为False，设置为False会大幅提高性能\n",
    "\n",
    "print(x2.sort_values('data1'))\n",
    "# 也可直接用Dataframe的排序方法：sort_values，sort_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B\n",
      "K0  A0  B0\n",
      "K1  A1  B1\n",
      "K2  A2  B2\n",
      "     C   D\n",
      "K0  C0  D0\n",
      "K2  C2  D2\n",
      "K3  C3  D3\n",
      "     A   B    C    D\n",
      "K0  A0  B0   C0   D0\n",
      "K1  A1  B1  NaN  NaN\n",
      "K2  A2  B2   C2   D2\n",
      "      A    B    C    D\n",
      "K0   A0   B0   C0   D0\n",
      "K1   A1   B1  NaN  NaN\n",
      "K2   A2   B2   C2   D2\n",
      "K3  NaN  NaN   C3   D3\n",
      "-----\n",
      "  key  data1\n",
      "0   b      1\n",
      "1   b      3\n",
      "2   a      2\n",
      "3   c      4\n",
      "4   a      5\n",
      "5   a      9\n",
      "6   b      7\n",
      "  key  date2\n",
      "0   a     11\n",
      "1   b      2\n",
      "2   d     33\n",
      "  key_1  data1 key_2  date2\n",
      "0     b      1     a     11\n",
      "1     b      3     b      2\n",
      "2     a      2     d     33\n",
      "  key  data1  date2\n",
      "0   b      1   11.0\n",
      "1   b      3    2.0\n",
      "2   a      2   33.0\n",
      "3   c      4    NaN\n",
      "4   a      5    NaN\n",
      "5   a      9    NaN\n",
      "6   b      7    NaN\n",
      "-----\n",
      "    A   B key\n",
      "0  A0  B0  K0\n",
      "1  A1  B1  K1\n",
      "2  A2  B2  K0\n",
      "3  A3  B3  K1\n",
      "     C   D\n",
      "K0  C0  D0\n",
      "K1  C1  D1\n",
      "    A   B key   C   D\n",
      "0  A0  B0  K0  C0  D0\n",
      "1  A1  B1  K1  C1  D1\n",
      "2  A2  B2  K0  C0  D0\n",
      "3  A3  B3  K1  C1  D1\n"
     ]
    }
   ],
   "source": [
    "# pd.join() → 直接通过索引链接\n",
    "\n",
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                     'B': ['B0', 'B1', 'B2']},\n",
    "                    index=['K0', 'K1', 'K2'])\n",
    "right = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D2', 'D3']},\n",
    "                     index=['K0', 'K2', 'K3'])\n",
    "print(left)\n",
    "print(right)\n",
    "print(left.join(right))\n",
    "print(left.join(right, how='outer'))  \n",
    "print('-----')\n",
    "# 等价于：pd.merge(left, right, left_index=True, right_index=True, how='outer')\n",
    "\n",
    "df1 = pd.DataFrame({'key':list('bbacaab'),\n",
    "                   'data1':[1,3,2,4,5,9,7]})\n",
    "df2 = pd.DataFrame({'key':list('abd'),\n",
    "                   'date2':[11,2,33]})\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(pd.merge(df1, df2, left_index=True, right_index=True, suffixes=('_1', '_2')))  \n",
    "print(df1.join(df2['date2']))\n",
    "print('-----')\n",
    "# suffixes=('_x', '_y')默认\n",
    "\n",
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                     'key': ['K0', 'K1', 'K0', 'K1']})\n",
    "right = pd.DataFrame({'C': ['C0', 'C1'],\n",
    "                      'D': ['D0', 'D1']},\n",
    "                     index=['K0', 'K1'])\n",
    "print(left)\n",
    "print(right)\n",
    "print(left.join(right, on = 'key'))\n",
    "# 等价于pd.merge(left, right, left_on='key', right_index=True, how='left', sort=False);\n",
    "# left的‘key’和right的index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key    values\n",
      "0   a  0.500524\n",
      "1   b  0.067579\n",
      "2   c  0.475227\n",
      "  key    values\n",
      "0   b  0.476006\n",
      "1   c  0.659367\n",
      "2   d  0.867953\n",
      "  key  values_x  values_y\n",
      "0   a  0.500524       NaN\n",
      "1   b  0.067579  0.476006\n",
      "2   c  0.475227  0.659367\n",
      "3   d       NaN  0.867953\n"
     ]
    }
   ],
   "source": [
    "#作业\n",
    "df1 = pd.DataFrame({'key':['a','b','c'],\n",
    "                   'values':np.random.rand(3)})\n",
    "df2 = pd.DataFrame({'key':['b','c','d'],\n",
    "                   'values':np.random.rand(3)})\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(pd.merge(df1,df2,on = 'key',how = 'outer'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lkey   values1\n",
      "0    a  0.525752\n",
      "1    b  0.616747\n",
      "2    c  0.589243\n",
      "  rkey   values2\n",
      "0    b  0.267440\n",
      "1    c  0.331919\n",
      "2    d  0.992953\n",
      "  lkey   values1 rkey   values2\n",
      "0    a  0.525752  NaN       NaN\n",
      "1    b  0.616747    b  0.267440\n",
      "2    c  0.589243    c  0.331919\n"
     ]
    }
   ],
   "source": [
    "#作业2\n",
    "df1 = pd.DataFrame({'lkey':['a','b','c'],\n",
    "                   'values1':np.random.rand(3)})\n",
    "df2 = pd.DataFrame({'rkey':['b','c','d'],\n",
    "                   'values2':np.random.rand(3)})\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(pd.merge(df1,df2,left_on = 'lkey',right_on = 'rkey',how = 'left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   values1\n",
      "0   a  0.754746\n",
      "1   b  0.707030\n",
      "2   c  0.638524\n",
      "    values2 values3\n",
      "b  0.357361       5\n",
      "c  0.538367       6\n",
      "d  0.126469       7\n",
      "  key   values1   values2 values3\n",
      "1   b  0.707030  0.357361       5\n",
      "2   c  0.638524  0.538367       6\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'key':['a','b','c'],\n",
    "                   'values1':np.random.rand(3)})\n",
    "df2 = pd.DataFrame({'values2':np.random.rand(3),\n",
    "                   'values3':['5','6','7']},index = ['b','c','d'])\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(pd.merge(df1,df2,left_on = 'key',right_index = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n【课程2.17】  连接与修补 concat、combine_first\\n\\n连接 - 沿轴执行连接操作\\n\\npd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,\\n          keys=None, levels=None, names=None, verify_integrity=False,\\n          copy=True)\\n \\n\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "【课程2.17】  连接与修补 concat、combine_first\n",
    "\n",
    "连接 - 沿轴执行连接操作\n",
    "\n",
    "pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "0    2\n",
      "1    3\n",
      "2    4\n",
      "dtype: int64\n",
      "a    1\n",
      "b    2\n",
      "c    2\n",
      "d    4\n",
      "e    3\n",
      "h    3\n",
      "dtype: int64\n",
      "-----\n",
      "     0    1\n",
      "a  1.0  NaN\n",
      "b  NaN  2.0\n",
      "c  2.0  NaN\n",
      "d  NaN  4.0\n",
      "e  NaN  3.0\n",
      "h  3.0  NaN\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# 连接：concat\n",
    "\n",
    "s1 = pd.Series([1,2,3])\n",
    "s2 = pd.Series([2,3,4])\n",
    "s3 = pd.Series([1,2,3],index = ['a','c','h'])\n",
    "s4 = pd.Series([2,3,4],index = ['b','e','d'])\n",
    "print(pd.concat([s1,s2]))\n",
    "print(pd.concat([s3,s4]).sort_index())\n",
    "print('-----')\n",
    "# 默认axis=0，行+行\n",
    "\n",
    "print(pd.concat([s3,s4], axis=1))\n",
    "print('-----')\n",
    "# axis=1,列+列，成为一个Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one  a    1\n",
      "     b    2\n",
      "     c    3\n",
      "two  b    2\n",
      "     c    3\n",
      "     d    4\n",
      "dtype: int64 <class 'pandas.core.series.Series'>\n",
      "MultiIndex(levels=[['one', 'two'], ['a', 'b', 'c', 'd']],\n",
      "           labels=[[0, 0, 0, 1, 1, 1], [0, 1, 2, 1, 2, 3]])\n",
      "-----\n",
      "   one  two\n",
      "a  1.0  NaN\n",
      "b  2.0  2.0\n",
      "c  3.0  3.0\n",
      "d  NaN  4.0 <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# 覆盖列名\n",
    "\n",
    "sre = pd.concat([s5,s6], keys = ['one','two'])\n",
    "print(sre,type(sre))\n",
    "print(sre.index)\n",
    "print('-----')\n",
    "# keys：序列，默认值无。使用传递的键作为最外层构建层次索引\n",
    "\n",
    "sre = pd.concat([s5,s6], axis=1, keys = ['one','two'])\n",
    "print(sre,type(sre))\n",
    "# axis = 1, 覆盖列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "a  1.0  NaN\n",
      "b  2.0  2.0\n",
      "c  3.0  3.0\n",
      "d  NaN  4.0\n",
      "   0  1\n",
      "b  2  2\n",
      "c  3  3\n",
      "     0    1\n",
      "a  1.0  NaN\n",
      "b  2.0  2.0\n",
      "d  NaN  4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# 连接方式：join，join_axes\n",
    "\n",
    "s5 = pd.Series([1,2,3],index = ['a','b','c'])\n",
    "s6 = pd.Series([2,3,4],index = ['b','c','d'])\n",
    "print(pd.concat([s5,s6], axis= 1))\n",
    "print(pd.concat([s5,s6], axis= 1, join='inner'))\n",
    "print(pd.concat([s5,s6], axis= 1, join_axes=[['a','b','d']]))\n",
    "# join：{'inner'，'outer'}，默认为“outer”。如何处理其他轴上的索引。outer为联合和inner为交集。\n",
    "# join_axes：指定联合的index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  NaN  3.0  5.0\n",
      "1 -4.6  NaN  NaN\n",
      "2  NaN  7.0  NaN\n",
      "      0    1    2\n",
      "1 -42.6  NaN -8.2\n",
      "2  -5.0  1.6  4.0\n",
      "     0    1    2\n",
      "0  NaN  3.0  5.0\n",
      "1 -4.6  NaN -8.2\n",
      "2 -5.0  7.0  4.0\n",
      "-----\n",
      "      0    1    2\n",
      "0   NaN  3.0  5.0\n",
      "1 -42.6  NaN -8.2\n",
      "2  -5.0  1.6  4.0\n"
     ]
    }
   ],
   "source": [
    "# 修补 pd.combine_first()\n",
    "\n",
    "df1 = pd.DataFrame([[np.nan, 3., 5.], [-4.6, np.nan, np.nan],[np.nan, 7., np.nan]])\n",
    "df2 = pd.DataFrame([[-42.6, np.nan, -8.2], [-5., 1.6, 4]],index=[1, 2])\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(df1.combine_first(df2))\n",
    "print('-----')\n",
    "# 根据index，df1的空值被df2替代\n",
    "# 如果df2的index多于df1，则更新到df1上，比如index=['a',1]\n",
    "\n",
    "df1.update(df2)\n",
    "print(df1)\n",
    "# update，直接df2覆盖df1，相同index位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    values1   values2\n",
      "a  0.385334  0.923559\n",
      "b  0.454325  0.299974\n",
      "c  0.350475  0.010534\n",
      "d  0.118790  0.556286\n",
      "----------\n",
      "    values1   values2\n",
      "e  0.163781  0.962305\n",
      "f  0.065241  0.587169\n",
      "g  0.278648  0.166870\n",
      "h  0.839526  0.320637\n",
      "----------\n",
      "    values1   values2\n",
      "a  0.385334  0.923559\n",
      "b  0.454325  0.299974\n",
      "c  0.350475  0.010534\n",
      "d  0.118790  0.556286\n",
      "e  0.163781  0.962305\n",
      "f  0.065241  0.587169\n",
      "g  0.278648  0.166870\n",
      "h  0.839526  0.320637\n"
     ]
    }
   ],
   "source": [
    "#作业\n",
    "df1 = pd.DataFrame({'values1':np.random.rand(4),\n",
    "                   'values2':np.random.rand(4)},index = ['a','b','c','d'])\n",
    "df2 = pd.DataFrame({'values1':np.random.rand(4),\n",
    "                   'values2':np.random.rand(4)},index = ['e','f','g','h'])\n",
    "print(df1)\n",
    "print('----------')\n",
    "print(df2)\n",
    "print(\"----------\")\n",
    "print(pd.concat([df1,df2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    values1   values2\n",
      "a  0.300639  0.776365\n",
      "b       NaN  0.835682\n",
      "c       NaN  0.448268\n",
      "d  0.452523  0.675224\n",
      "   values1  values2\n",
      "a        8        6\n",
      "b        3        3\n",
      "c        3        4\n",
      "d        3        8\n",
      "    values1   values2\n",
      "a  0.300639  0.776365\n",
      "b  3.000000  0.835682\n",
      "c  3.000000  0.448268\n",
      "d  0.452523  0.675224\n"
     ]
    }
   ],
   "source": [
    "#作业2\n",
    "df1 = pd.DataFrame({'values1':np.random.rand(4),\n",
    "                   'values2':np.random.rand(4)},index = ['a','b','c','d'])\n",
    "df1['values1'][[1,2]]=np.nan\n",
    "print(df1)\n",
    "df2 = pd.DataFrame({'values1':np.random.randint(9,size = 4),\n",
    "                   'values2':np.random.randint(9,size = 4)},index = ['a','b','c','d'])\n",
    "print(df2)\n",
    "\n",
    "print(df1.combine_first(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n【课程2.18】  去重及替换\\n\\n.duplicated / .replace\\n \\n'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "【课程2.18】  去重及替换\n",
    "\n",
    ".duplicated / .replace\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1      True\n",
      "2      True\n",
      "3      True\n",
      "4     False\n",
      "5      True\n",
      "6      True\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10     True\n",
      "11     True\n",
      "12     True\n",
      "dtype: bool\n",
      "0    1\n",
      "4    2\n",
      "7    3\n",
      "8    4\n",
      "9    5\n",
      "dtype: int64\n",
      "-----\n",
      "0    1\n",
      "4    2\n",
      "7    3\n",
      "8    4\n",
      "9    5\n",
      "dtype: int64\n",
      "-----\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "Name: key2, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 去重 .duplicated\n",
    "\n",
    "s = pd.Series([1,1,1,1,2,2,2,3,4,5,5,5,5])\n",
    "print(s.duplicated())\n",
    "print(s[s.duplicated() == False])\n",
    "print('-----')\n",
    "# 判断是否重复\n",
    "# 通过布尔判断，得到不重复的值\n",
    "\n",
    "s_re = s.drop_duplicates()\n",
    "print(s_re)\n",
    "print('-----')\n",
    "# drop.duplicates移除重复\n",
    "# inplace参数：是否替换原值，默认False\n",
    "\n",
    "df = pd.DataFrame({'key1':['a','a',3,4,5],\n",
    "                  'key2':['a','a','b','b','c']})\n",
    "print(df.duplicated())\n",
    "print(df['key2'].duplicated())\n",
    "# Dataframe中使用duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1      s\n",
      "2      c\n",
      "3    NaN\n",
      "4    NaN\n",
      "5      z\n",
      "6      s\n",
      "7      d\n",
      "dtype: object\n",
      "0    NaN\n",
      "1    NaN\n",
      "2      c\n",
      "3    NaN\n",
      "4    NaN\n",
      "5      z\n",
      "6    NaN\n",
      "7      d\n",
      "dtype: object\n",
      "0    hello world!\n",
      "1             123\n",
      "2               c\n",
      "3    hello world!\n",
      "4    hello world!\n",
      "5               z\n",
      "6             123\n",
      "7               d\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 替换 .replace\n",
    "\n",
    "s = pd.Series(list('ascaazsd'))\n",
    "print(s.replace('a', np.nan))\n",
    "print(s.replace(['a','s'] ,np.nan))\n",
    "print(s.replace({'a':'hello world!','s':123}))\n",
    "# 可一次性替换一个值或多个值\n",
    "# 可传入列表或字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n【课程2.19】  数据分组\\n\\n分组统计 - groupby功能\\n\\n① 根据某些条件将数据拆分成组\\n② 对每个组独立应用函数\\n③ 将结果合并到一个数据结构中\\n\\nDataframe在行（axis=0）或列（axis=1）上进行分组，将一个函数应用到各个分组并产生一个新值，然后函数执行结果被合并到最终的结果对象中。\\n\\ndf.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\\n \\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "【课程2.19】  数据分组\n",
    "\n",
    "分组统计 - groupby功能\n",
    "\n",
    "① 根据某些条件将数据拆分成组\n",
    "② 对每个组独立应用函数\n",
    "③ 将结果合并到一个数据结构中\n",
    "\n",
    "Dataframe在行（axis=0）或列（axis=1）上进行分组，将一个函数应用到各个分组并产生一个新值，然后函数执行结果被合并到最终的结果对象中。\n",
    "\n",
    "df.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A      B         C         D\n",
      "0  foo    one  1.017680 -0.903735\n",
      "1  bar    one -0.718537  1.082558\n",
      "2  foo    two  1.040767  1.993288\n",
      "3  bar  three  1.070717 -0.221820\n",
      "4  foo    two  0.635996  2.107791\n",
      "5  bar    two -0.595759  0.977104\n",
      "6  foo    one -1.574514 -0.366098\n",
      "7  foo  three  1.901825  0.003268\n",
      "------\n",
      "            C         D\n",
      "A                      \n",
      "bar -0.081193  0.612614\n",
      "foo  0.604351  0.566903 <class 'pandas.core.frame.DataFrame'> \n",
      " Index(['C', 'D'], dtype='object')\n",
      "                  C         D\n",
      "A   B                        \n",
      "bar one   -0.718537  1.082558\n",
      "    three  1.070717 -0.221820\n",
      "    two   -0.595759  0.977104\n",
      "foo one   -0.278417 -0.634916\n",
      "    three  1.901825  0.003268\n",
      "    two    0.838381  2.050539 <class 'pandas.core.frame.DataFrame'> \n",
      " Index(['C', 'D'], dtype='object')\n",
      "A\n",
      "bar    0.612614\n",
      "foo    0.566903\n",
      "Name: D, dtype: float64 <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# 分组\n",
    "\n",
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar','foo', 'bar', 'foo', 'foo'],\n",
    "                   'B' : ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],\n",
    "                   'C' : np.random.randn(8),\n",
    "                   'D' : np.random.randn(8)})\n",
    "print(df)\n",
    "print('------')\n",
    "# 直接分组得到一个groupby对象，是一个中间数据，没有进行计算\n",
    "\n",
    "a = df.groupby('A').mean()\n",
    "b = df.groupby(['A','B']).mean()\n",
    "#c = df.groupby(['A'])['D'].mean()  # 以A分组，算D的平均值\n",
    "print(a,type(a),'\\n',a.columns)\n",
    "print(b,type(b),'\\n',b.columns)\n",
    "print(c,type(c))\n",
    "# 通过分组后的计算，得到一个新的dataframe\n",
    "# 默认axis = 0，以行来分组\n",
    "# 可单个或多个（[]）列分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X  Y\n",
      "0  A  1\n",
      "1  B  4\n",
      "2  A  3\n",
      "3  B  2\n",
      "<pandas.core.groupby.groupby.DataFrameGroupBy object at 0x0000000008B1E780> <class 'pandas.core.groupby.groupby.DataFrameGroupBy'>\n",
      "-----\n",
      "[('A',    X  Y\n",
      "0  A  1\n",
      "2  A  3), ('B',    X  Y\n",
      "1  B  4\n",
      "3  B  2)] → 可迭代对象，直接生成list\n",
      "\n",
      "('A',    X  Y\n",
      "0  A  1\n",
      "2  A  3) → 以元祖形式显示\n",
      "\n",
      "A\n",
      "   X  Y\n",
      "0  A  1\n",
      "2  A  3\n",
      "###\n",
      "B\n",
      "   X  Y\n",
      "1  B  4\n",
      "3  B  2\n",
      "###\n",
      "-----\n",
      "   X  Y\n",
      "0  A  1\n",
      "2  A  3 \n",
      "\n",
      "   X  Y\n",
      "1  B  4\n",
      "3  B  2 \n",
      "\n",
      "-----\n",
      "{'A': Int64Index([0, 2], dtype='int64'), 'B': Int64Index([1, 3], dtype='int64')}\n",
      "Int64Index([0, 2], dtype='int64')\n",
      "-----\n",
      "X\n",
      "A    2\n",
      "B    2\n",
      "dtype: int64 <class 'pandas.core.series.Series'>\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 分组 - 可迭代对象\n",
    "\n",
    "df = pd.DataFrame({'X' : ['A', 'B', 'A', 'B'], 'Y' : [1, 4, 3, 2]})\n",
    "print(df)\n",
    "print(df.groupby('X'), type(df.groupby('X')))\n",
    "print('-----')\n",
    "\n",
    "print(list(df.groupby('X')), '→ 可迭代对象，直接生成list\\n')\n",
    "print(list(df.groupby('X'))[0], '→ 以元祖形式显示\\n')\n",
    "for n,g in df.groupby('X'):\n",
    "    print(n)\n",
    "    print(g)\n",
    "    print('###')\n",
    "print('-----')\n",
    "# n是组名，g是分组后的Dataframe\n",
    "\n",
    "print(df.groupby(['X']).get_group('A'),'\\n')\n",
    "print(df.groupby(['X']).get_group('B'),'\\n')\n",
    "print('-----')\n",
    "# .get_group()提取分组后的组\n",
    "\n",
    "grouped = df.groupby(['X'])\n",
    "print(grouped.groups)\n",
    "print(grouped.groups['A'])  # 也可写：df.groupby('X').groups['A']\n",
    "print('-----')\n",
    "# .groups：将分组后的groups转为dict\n",
    "# 可以字典索引方法来查看groups里的元素\n",
    "\n",
    "sz = grouped.size()\n",
    "print(sz,type(sz))\n",
    "print('-----')\n",
    "# .size()：查看分组后的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A      B         C         D\n",
      "0  foo    one  1.446015  1.780335\n",
      "1  bar    one -0.333256  2.805956\n",
      "2  foo    two  0.667509  1.492366\n",
      "3  bar  three  0.576641 -0.475213\n",
      "4  foo    two  1.011619  0.455949\n",
      "5  bar    two -1.537046  0.746770\n",
      "6  foo    one  1.349249 -1.022693\n",
      "7  foo  three  0.661167 -0.074151\n",
      "{('bar', 'one'): Int64Index([1], dtype='int64'), ('bar', 'three'): Int64Index([3], dtype='int64'), ('bar', 'two'): Int64Index([5], dtype='int64'), ('foo', 'one'): Int64Index([0, 6], dtype='int64'), ('foo', 'three'): Int64Index([7], dtype='int64'), ('foo', 'two'): Int64Index([2, 4], dtype='int64')}\n",
      "Int64Index([7], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar','foo', 'bar', 'foo', 'foo'],\n",
    "                   'B' : ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],\n",
    "                   'C' : np.random.randn(8),\n",
    "                   'D' : np.random.randn(8)})\n",
    "grouped = df.groupby(['A','B']).groups\n",
    "print(df)\n",
    "print(grouped)\n",
    "print(grouped[('foo', 'three')])\n",
    "# 按照两个列进行分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      data1     data2 key1 key2\n",
      "0  0.112854  0.907615    a  one\n",
      "1  0.427279  0.928143    b  two\n",
      "data1    float64\n",
      "data2    float64\n",
      "key1      object\n",
      "key2      object\n",
      "dtype: object\n",
      "-----\n",
      "float64\n",
      "      data1     data2\n",
      "0  0.112854  0.907615\n",
      "1  0.427279  0.928143\n",
      "##\n",
      "object\n",
      "  key1 key2\n",
      "0    a  one\n",
      "1    b  two\n",
      "##\n"
     ]
    }
   ],
   "source": [
    "# 其他轴上的分组\n",
    "\n",
    "df = pd.DataFrame({'data1':np.random.rand(2),\n",
    "                  'data2':np.random.rand(2),\n",
    "                  'key1':['a','b'],\n",
    "                  'key2':['one','two']})\n",
    "print(df)\n",
    "print(df.dtypes)\n",
    "print('-----')\n",
    "for n,p in df.groupby(df.dtypes, axis=1):\n",
    "    print(n)\n",
    "    print(p)\n",
    "    print('##')\n",
    "# 按照值类型分列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d\n",
      "0   0   1   2   3\n",
      "1   4   5   6   7\n",
      "2   8   9  10  11\n",
      "3  12  13  14  15\n",
      "-----\n",
      "   one  two\n",
      "0    1    5\n",
      "1    9   13\n",
      "2   17   21\n",
      "3   25   29\n",
      "-----\n",
      "a      one\n",
      "b      one\n",
      "c      two\n",
      "d      two\n",
      "e    three\n",
      "dtype: object \n",
      "\n",
      "one      2\n",
      "three    1\n",
      "two      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 通过字典或者Series分组\n",
    "\n",
    "df = pd.DataFrame(np.arange(16).reshape(4,4),\n",
    "                  columns = ['a','b','c','d'])\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "mapping = {'a':'one','b':'one','c':'two','d':'two','e':'three'}\n",
    "by_column = df.groupby(mapping, axis = 1)\n",
    "print(by_column.sum())\n",
    "print('-----')\n",
    "# mapping中，a、b列对应的为one，c、d列对应的为two，以字典来分组\n",
    "\n",
    "s = pd.Series(mapping)\n",
    "print(s,'\\n')\n",
    "print(s.groupby(s).count())\n",
    "# s中，index中a、b对应的为one，c、d对应的为two，以Series来分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      a   b   c   d\n",
      "abc   0   1   2   3\n",
      "bcd   4   5   6   7\n",
      "aa    8   9  10  11\n",
      "b    12  13  14  15 \n",
      "\n",
      "    a   b   c   d\n",
      "1  12  13  14  15\n",
      "2   8   9  10  11\n",
      "3   4   6   8  10\n"
     ]
    }
   ],
   "source": [
    "# 通过函数分组\n",
    "\n",
    "df = pd.DataFrame(np.arange(16).reshape(4,4),\n",
    "                  columns = ['a','b','c','d'],\n",
    "                 index = ['abc','bcd','aa','b'])\n",
    "print(df,'\\n')\n",
    "print(df.groupby(len).sum())\n",
    "# 按照字母长度分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.groupby.SeriesGroupBy object at 0x00000000091B4518>\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "dtype: int64 → first：非NaN的第一个值\n",
      "\n",
      "1    10\n",
      "2    20\n",
      "3    30\n",
      "dtype: int64 → last：非NaN的最后一个值\n",
      "\n",
      "1    11\n",
      "2    22\n",
      "3    33\n",
      "dtype: int64 → sum：非NaN的和\n",
      "\n",
      "1     5.5\n",
      "2    11.0\n",
      "3    16.5\n",
      "dtype: float64 → mean：非NaN的平均值\n",
      "\n",
      "1     5.5\n",
      "2    11.0\n",
      "3    16.5\n",
      "dtype: float64 → median：非NaN的算术中位数\n",
      "\n",
      "1    2\n",
      "2    2\n",
      "3    2\n",
      "dtype: int64 → count：非NaN的值\n",
      "\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "dtype: int64 → min、max：非NaN的最小值、最大值\n",
      "\n",
      "1     6.363961\n",
      "2    12.727922\n",
      "3    19.091883\n",
      "dtype: float64 → std，var：非NaN的标准差和方差\n",
      "\n",
      "1    10\n",
      "2    40\n",
      "3    90\n",
      "dtype: int64 → prod：非NaN的积\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 分组计算函数方法\n",
    "\n",
    "s = pd.Series([1, 2, 3, 10, 20, 30], index = [1, 2, 3, 1, 2, 3])\n",
    "grouped = s.groupby(level=0)  # 唯一索引用.groupby(level=0)，将同一个index的分为一组\n",
    "print(grouped)\n",
    "print(grouped.first(),'→ first：非NaN的第一个值\\n')\n",
    "print(grouped.last(),'→ last：非NaN的最后一个值\\n')\n",
    "print(grouped.sum(),'→ sum：非NaN的和\\n')\n",
    "print(grouped.mean(),'→ mean：非NaN的平均值\\n')\n",
    "print(grouped.median(),'→ median：非NaN的算术中位数\\n')\n",
    "print(grouped.count(),'→ count：非NaN的值\\n')\n",
    "print(grouped.min(),'→ min、max：非NaN的最小值、最大值\\n')\n",
    "print(grouped.std(),'→ std，var：非NaN的标准差和方差\\n')\n",
    "print(grouped.prod(),'→ prod：非NaN的积\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a         b         c         d\n",
      "0  1  0.357881  0.348211  0.399857\n",
      "1  1  0.861220  0.308164  0.587618\n",
      "2  2  0.174413  0.692796  0.071603\n",
      "3  2  0.499483  0.794074  0.765352\n",
      "          b                   c                   d          \n",
      "       mean       sum      mean       sum      mean       sum\n",
      "a                                                            \n",
      "1  0.609550  1.219101  0.328188  0.656375  0.493738  0.987475\n",
      "2  0.336948  0.673895  0.743435  1.486870  0.418477  0.836955\n",
      "    result1   result2\n",
      "a                    \n",
      "1  0.609550  1.219101\n",
      "2  0.336948  0.673895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# 多函数计算：agg()\n",
    "\n",
    "df = pd.DataFrame({'a':[1,1,2,2],\n",
    "                  'b':np.random.rand(4),\n",
    "                  'c':np.random.rand(4),\n",
    "                  'd':np.random.rand(4),})\n",
    "print(df)\n",
    "print(df.groupby('a').agg(['mean',np.sum]))\n",
    "print(df.groupby('a')['b'].agg({'result1':np.mean,\n",
    "                               'result2':np.sum}))\n",
    "# 函数写法可以用str，或者np.方法\n",
    "# 可以通过list，dict传入，当用dict时，key名为columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A  B   C         D         E\n",
      "0    one  h  10 -2.455333  0.000409\n",
      "1    two  h  12  0.818387  0.826707\n",
      "2  three  h  14  0.220430  0.176853\n",
      "3    one  h  16  1.059636  0.847430\n",
      "4    two  f  18 -0.153090  0.239909\n",
      "5  three  f  20 -0.175375  0.434072\n",
      "6    one  f  22 -1.439173  0.191124\n",
      "7    two  f  24 -0.227953  0.230091\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "以B分组，求出每组的均值，求和，最大值，最小值：\n",
      "      C                       D                                       E  \\\n",
      "  mean sum amax amin      mean       sum      amax      amin      mean   \n",
      "B                                                                        \n",
      "f   21  84   24   18 -0.498898 -1.995591 -0.153090 -1.439173  0.273799   \n",
      "h   13  52   16   10 -0.089220 -0.356880  1.059636 -2.455333  0.462850   \n",
      "\n",
      "                                 \n",
      "        sum      amax      amin  \n",
      "B                                \n",
      "f  1.095195  0.434072  0.191124  \n",
      "h  1.851400  0.847430  0.000409  \n"
     ]
    }
   ],
   "source": [
    "#作业\n",
    "df = pd.DataFrame({'A':['one','two','three','one','two','three','one','two'],\n",
    "                 'B':['h','h','h','h','f','f','f','f'],\n",
    "                  'C':np.arange(10,26,2),\n",
    "                  'D':np.random.randn(8),\n",
    "                  'E':np.random.rand(8)})\n",
    "print(df)\n",
    "gd = df.groupby('A')\n",
    "#print('C的分组平均值：\\n',gd.mean())\n",
    "print('-------')\n",
    "gd1 = df.groupby(['A','B'])\n",
    "#print('D的分组求和：\\n',gd1.sum())\n",
    "print('-------')\n",
    "#print('以A分组，筛选出分组后的第一组数据为：\\n',gd.groups,'\\n------')\n",
    "print('-------')\n",
    "gd3 = df.groupby(df.dtypes,axis = 1)\n",
    "#print(\"按照数值类型分组，求和\\n:\",gd3.sum())\n",
    "mapping = {'C':'r','D':'r'}\n",
    "gd4 = df.groupby(mapping,axis = 1)\n",
    "#print('将C，D分为一组，并计算求和为：\\n',gd4.sum())\n",
    "gd5 = df.groupby('B')\n",
    "print('以B分组，求出每组的均值，求和，最大值，最小值：\\n',gd5.agg([np.mean,np.sum,np.max,np.min]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n【课程2.20】  分组转换及一般性“拆分-应用-合并”\\n\\ntransform / apply\\n \\n'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "【课程2.20】  分组转换及一般性“拆分-应用-合并”\n",
    "\n",
    "transform / apply\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      data1     data2 key1 key2\n",
      "0  0.875976  0.037006    a  one\n",
      "1  0.343192  0.381894    a  two\n",
      "2  0.567924  0.555000    b  one\n",
      "3  0.749539  0.753558    b  two\n",
      "4  0.427945  0.271670    a  one\n",
      "         data1     data2\n",
      "key1                    \n",
      "a     0.549038  0.230190\n",
      "b     0.658731  0.654279\n",
      "   mean_data1_x  mean_data2_x mean_key1 mean_key2  mean_data1_y  mean_data2_y\n",
      "0      0.875976      0.037006         a       one      0.549038      0.230190\n",
      "1      0.343192      0.381894         a       two      0.549038      0.230190\n",
      "4      0.427945      0.271670         a       one      0.549038      0.230190\n",
      "2      0.567924      0.555000         b       one      0.658731      0.654279\n",
      "3      0.749539      0.753558         b       two      0.658731      0.654279\n",
      "-----\n",
      "         data1     data2\n",
      "key2                    \n",
      "one   0.623948  0.287892\n",
      "two   0.546366  0.567726\n",
      "      data1     data2\n",
      "0  0.623948  0.287892\n",
      "1  0.546366  0.567726\n",
      "2  0.623948  0.287892\n",
      "3  0.546366  0.567726\n",
      "4  0.623948  0.287892\n"
     ]
    }
   ],
   "source": [
    "# 数据分组转换,transform\n",
    "\n",
    "df = pd.DataFrame({'data1':np.random.rand(5),\n",
    "                  'data2':np.random.rand(5),\n",
    "                  'key1':list('aabba'),\n",
    "                  'key2':['one','two','one','two','one']})\n",
    "k_mean = df.groupby('key1').mean()\n",
    "print(df)\n",
    "print(k_mean)\n",
    "print(pd.merge(df,k_mean,left_on='key1',right_index=True).add_prefix('mean_'))  # .add_prefix('mean_')：添加前缀\n",
    "print('-----')\n",
    "# 通过分组、合并，得到一个包含均值的Dataframe\n",
    "\n",
    "print(df.groupby('key2').mean()) # 按照key2分组求均值\n",
    "print(df.groupby('key2').transform(np.mean))\n",
    "# data1、data2每个位置元素取对应分组列的均值\n",
    "# 字符串不能进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               data1     data2\n",
      "key1                          \n",
      "a    count  3.000000  3.000000\n",
      "     mean   0.529457  0.406671\n",
      "     std    0.454543  0.177608\n",
      "     min    0.060430  0.222985\n",
      "     25%    0.310196  0.321254\n",
      "     50%    0.559961  0.419524\n",
      "     75%    0.763970  0.498513\n",
      "     max    0.967979  0.577503\n",
      "b    count  2.000000  2.000000\n",
      "     mean   0.779509  0.516088\n",
      "     std    0.154199  0.661813\n",
      "     min    0.670474  0.048116\n",
      "     25%    0.724992  0.282102\n",
      "     50%    0.779509  0.516088\n",
      "     75%    0.834027  0.750074\n",
      "     max    0.888545  0.984061\n",
      "           data1     data2 key1 key2\n",
      "key1                                \n",
      "a    0  0.559961  0.419524    a  one\n",
      "     1  0.060430  0.222985    a  two\n",
      "b    2  0.888545  0.984061    b  one\n",
      "     3  0.670474  0.048116    b  two \n",
      "\n",
      "key1   \n",
      "a     0    0.419524\n",
      "      1    0.222985\n",
      "      4    0.577503\n",
      "b     2    0.984061\n",
      "      3    0.048116\n",
      "Name: data2, dtype: float64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# 一般化Groupby方法：apply\n",
    "\n",
    "df = pd.DataFrame({'data1':np.random.rand(5),\n",
    "                  'data2':np.random.rand(5),\n",
    "                  'key1':list('aabba'),\n",
    "                  'key2':['one','two','one','two','one']})\n",
    "\n",
    "print(df.groupby('key1').apply(lambda x: x.describe()))\n",
    "# apply直接运行其中的函数\n",
    "# 这里为匿名函数，直接描述分组后的统计量\n",
    "\n",
    "def f_df1(d,n):\n",
    "    return(d.sort_index()[:n])\n",
    "def f_df2(d,k1):\n",
    "    return(d[k1])\n",
    "print(df.groupby('key1').apply(f_df1,2),'\\n')\n",
    "print(df.groupby('key1').apply(f_df2,'data2'))\n",
    "print(type(df.groupby('key1').apply(f_df2,'data2')))\n",
    "# f_df1函数：返回排序后的前n行数据\n",
    "# f_df2函数：返回分组后表的k1列，结果为Series，层次化索引\n",
    "# 直接运行f_df函数\n",
    "# 参数直接写在后面，也可以为.apply(f_df,n = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建df为：\n",
      "       data1     data2 key\n",
      "0  0.695079  0.005279   a\n",
      "1  0.432306  0.972278   a\n",
      "2  0.172199  0.976682   b\n",
      "3  0.547660  0.314175   b\n",
      "4  0.712198  0.336256   a\n",
      "5  0.865091  0.671598   b\n",
      "6  0.229749  0.253486   a\n",
      "7  0.553972  0.536586   b\n",
      "      data1     data2 key  data1_mean  data2_mean\n",
      "0  0.695079  0.005279   a    0.517333    0.391825\n",
      "1  0.432306  0.972278   a    0.517333    0.391825\n",
      "2  0.172199  0.976682   b    0.534731    0.624760\n",
      "3  0.547660  0.314175   b    0.534731    0.624760\n",
      "4  0.712198  0.336256   a    0.517333    0.391825\n",
      "5  0.865091  0.671598   b    0.534731    0.624760\n",
      "6  0.229749  0.253486   a    0.517333    0.391825\n",
      "7  0.553972  0.536586   b    0.534731    0.624760\n"
     ]
    }
   ],
   "source": [
    "#作业\n",
    "df = pd.DataFrame({'data1':np.random.rand(8),\n",
    "                  'data2':np.random.rand(8),\n",
    "                  'key':['a','a','b','b','a','b','a','b']})\n",
    "print('创建df为：\\n',df)\n",
    "df1 = df.groupby('key').transform(np.mean)\n",
    "df2 = df.join(df1,rsuffix='_mean')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n【课程2.21】  透视表及交叉表\\n\\n类似excel数据透视 - pivot table / crosstab\\n \\n'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "【课程2.21】  透视表及交叉表\n",
    "\n",
    "类似excel数据透视 - pivot table / crosstab\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date key    values\n",
      "0 2017-05-01   a  3.884404\n",
      "1 2017-05-02   b  4.856489\n",
      "2 2017-05-03   c  3.827493\n",
      "3 2017-05-01   d  7.185058\n",
      "4 2017-05-02   a  8.972539\n",
      "5 2017-05-03   b  9.954756\n",
      "6 2017-05-01   c  9.072155\n",
      "7 2017-05-02   d  2.527083\n",
      "8 2017-05-03   a  0.359281\n",
      "-----\n",
      "key                a         b         c         d\n",
      "date                                              \n",
      "2017-05-01  3.884404       NaN  9.072155  7.185058\n",
      "2017-05-02  8.972539  4.856489       NaN  2.527083\n",
      "2017-05-03  0.359281  9.954756  3.827493       NaN\n",
      "-----\n",
      "                values\n",
      "date       key        \n",
      "2017-05-01 a       1.0\n",
      "           c       1.0\n",
      "           d       1.0\n",
      "2017-05-02 a       1.0\n",
      "           b       1.0\n",
      "           d       1.0\n",
      "2017-05-03 a       1.0\n",
      "           b       1.0\n",
      "           c       1.0\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 透视表：pivot_table\n",
    "# pd.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')\n",
    "\n",
    "date = ['2017-5-1','2017-5-2','2017-5-3']*3\n",
    "rng = pd.to_datetime(date)\n",
    "df = pd.DataFrame({'date':rng,\n",
    "                   'key':list('abcdabcda'),\n",
    "                  'values':np.random.rand(9)*10})\n",
    "print(df)\n",
    "print('-----')\n",
    "print(pd.pivot_table(df, values = 'values', index = 'date', columns = 'key', aggfunc=np.sum))  # 也可以写 aggfunc='sum'\n",
    "print('-----')\n",
    "# data：DataFrame对象\n",
    "# values：要聚合的列或列的列表\n",
    "# index：数据透视表的index，从原数据的列中筛选\n",
    "# columns：数据透视表的columns，从原数据的列中筛选\n",
    "# aggfunc：用于聚合的函数，默认为numpy.mean，支持numpy计算方法\n",
    "\n",
    "print(pd.pivot_table(df, values = 'values', index = ['date','key'], aggfunc=len))\n",
    "print('-----')\n",
    "# 这里就分别以date、key共同做数据透视，值为values：统计不同（date，key）情况下values的平均值\n",
    "# aggfunc=len(或者count)：计数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B    C\n",
      "0  1  3  1.0\n",
      "1  2  3  1.0\n",
      "2  2  4  NaN\n",
      "3  2  4  1.0\n",
      "4  2  4  1.0\n",
      "-----\n",
      "B  3  4\n",
      "A      \n",
      "1  1  0\n",
      "2  1  3\n",
      "-----\n",
      "B    3    4\n",
      "A          \n",
      "1  0.2  0.0\n",
      "2  0.2  0.6\n",
      "-----\n",
      "B    3    4\n",
      "A          \n",
      "1  1.0  NaN\n",
      "2  1.0  2.0\n",
      "-----\n",
      "B      3    4  All\n",
      "A                 \n",
      "1    1.0  NaN  1.0\n",
      "2    1.0  2.0  3.0\n",
      "All  2.0  2.0  4.0\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# 交叉表：crosstab\n",
    "# 默认情况下，crosstab计算因子的频率表，比如用于str的数据透视分析\n",
    "# pd.crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, dropna=True, normalize=False)\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 2, 2, 2],\n",
    "                   'B': [3, 3, 4, 4, 4],\n",
    "                   'C': [1, 1, np.nan, 1, 1]})\n",
    "print(df)\n",
    "print('-----')\n",
    "\n",
    "print(pd.crosstab(df['A'],df['B']))\n",
    "print('-----')\n",
    "# 如果crosstab只接收两个Series，它将提供一个频率表。\n",
    "# 用A的唯一值，统计B唯一值的出现次数\n",
    "\n",
    "print(pd.crosstab(df['A'],df['B'],normalize=True))\n",
    "print('-----')\n",
    "# normalize：默认False，将所有值除以值的总和进行归一化 → 为True时候显示百分比\n",
    "\n",
    "print(pd.crosstab(df['A'],df['B'],values=df['C'],aggfunc=np.sum))\n",
    "print('-----')\n",
    "# values：可选，根据因子聚合的值数组\n",
    "# aggfunc：可选，如果未传递values数组，则计算频率表，如果传递数组，则按照指定计算\n",
    "# 这里相当于以A和B界定分组，计算出每组中第三个系列C的值\n",
    "\n",
    "print(pd.crosstab(df['A'],df['B'],values=df['C'],aggfunc=np.sum, margins=True))\n",
    "print('-----')\n",
    "# margins：布尔值，默认值False，添加行/列边距（小计）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建df为：\n",
      "        A  B   C         D         E\n",
      "0    one  h  10  0.302958  0.174578\n",
      "1    two  h  12 -1.119137  0.688343\n",
      "2  three  h  14  0.469234  0.971805\n",
      "3    one  h  16 -0.753177  0.754472\n",
      "4    two  f  18  0.381795  0.798143\n",
      "5  three  f  20 -1.592026  0.402339\n",
      "6    one  f  22 -1.409808  0.021807\n",
      "7    two  f  24 -0.474850  0.526172\n",
      "以A列聚合，求出C，D的平均值为：\n",
      "         C         D\n",
      "A                  \n",
      "one    16 -0.620009\n",
      "three  17 -0.561396\n",
      "two    18 -0.404064\n",
      "以A,B列聚合，求出D,E的均值,求和为：\n",
      "              mean                 sum          \n",
      "                D         E         D         E\n",
      "A     B                                        \n",
      "one   f -1.409808  0.021807 -1.409808  0.021807\n",
      "      h -0.225109  0.464525 -0.450218  0.929050\n",
      "three f -1.592026  0.402339 -1.592026  0.402339\n",
      "      h  0.469234  0.971805  0.469234  0.971805\n",
      "two   f -0.046528  0.662157 -0.093056  1.324315\n",
      "      h -1.119137  0.688343 -1.119137  0.688343\n",
      "以B聚合，计算A列的元素频率为：\n",
      " A  one  three  two\n",
      "B                 \n",
      "f    1      1    2\n",
      "h    2      1    1\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A' : ['one', 'two', 'three', 'one','two', 'three', 'one', 'two'],\n",
    "                   'B' : ['h', 'h', 'h', 'h', 'f', 'f', 'f', 'f'],\n",
    "                   'C' : np.arange(10,26,2),\n",
    "                   'D' : np.random.randn(8),\n",
    "                   'E':np.random.rand(8)})\n",
    "\n",
    "print('创建df为：\\n',df)\n",
    "print('以A列聚合，求出C，D的平均值为：\\n',pd.pivot_table(df,values = ['C','D'],index = 'A',aggfunc=np.mean))\n",
    "print('以A,B列聚合，求出D,E的均值,求和为：\\n',pd.pivot_table(df,values = ['D','E'],index = ['A','B'],aggfunc=[np.mean,np.sum]))\n",
    "print('以B聚合，计算A列的元素频率为：\\n',pd.crosstab(df['B'],df['A']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n【课程2.22】  数据读取\\n\\n核心：read_table, read_csv, read_excel\\n \\n'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "【课程2.22】  数据读取\n",
    "\n",
    "核心：read_table, read_csv, read_excel\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     va1  va3  va4\n",
      "va2               \n",
      "2      1    3    4\n",
      "3      2    4    5\n",
      "4      3    5    6\n",
      "5      4    6    7\n"
     ]
    }
   ],
   "source": [
    "# 读取普通分隔数据：read_table\n",
    "# 可以读取txt，csv\n",
    "\n",
    "import os\n",
    "os.chdir('C:/Users/Administrator/Desktop/')\n",
    "\n",
    "data1 = pd.read_table('data1.txt', delimiter=',',header = 0, index_col=1)\n",
    "print(data1)\n",
    "# delimiter：用于拆分的字符，也可以用sep：sep = ','\n",
    "# header：用做列名的序号，默认为0（第一行）\n",
    "# index_col：指定某列为行索引，否则自动索引0, 1, .....\n",
    "\n",
    "# read_table主要用于读取简单的数据，txt/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-257-937d290214a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 先熟悉一下excel怎么导出csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data2.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# engine：使用的分析引擎。可以选择C或者是python。C引擎快但是Python引擎功能更加完备。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1022\u001b[0m                                  ' \"c\", \"python\", or' ' \"python-fwf\")'.format(\n\u001b[0;32m   1023\u001b[0m                                      engine=engine))\n\u001b[1;32m-> 1024\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, **kwds)\u001b[0m\n\u001b[0;32m   2075\u001b[0m         f, handles = _get_handle(f, mode, encoding=self.encoding,\n\u001b[0;32m   2076\u001b[0m                                  \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2077\u001b[1;33m                                  memory_map=self.memory_map)\n\u001b[0m\u001b[0;32m   2078\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data2.csv'"
     ]
    }
   ],
   "source": [
    "# 读取csv数据：read_csv\n",
    "# 先熟悉一下excel怎么导出csv\n",
    "\n",
    "data2 = pd.read_csv('data2.csv',engine = 'python')\n",
    "print(data2.head())\n",
    "# engine：使用的分析引擎。可以选择C或者是python。C引擎快但是Python引擎功能更加完备。\n",
    "# encoding：指定字符集类型，即编码，通常指定为'utf-8'\n",
    "\n",
    "# 大多数情况先将excel导出csv，再读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取excel数据：read_excel\n",
    "\n",
    "data3 = pd.read_excel('地市级党委书记数据库（2000-10）.xlsx',sheetname='中国人民共和国地市级党委书记数据库（2000-10）',header=0)\n",
    "print(data3)\n",
    "# io ：文件路径。\n",
    "# sheetname：返回多表使用sheetname=[0,1],若sheetname=None是返回全表 → ① int/string 返回的是dataframe ②而none和list返回的是dict\n",
    "# header：指定列名行，默认0，即取第一行\n",
    "# index_col：指定列为索引列，也可以使用u”strings”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
